{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e260f146-9844-4854-a29c-7ef08829e4e7",
   "metadata": {},
   "source": [
    "# Export YoloV5 model to ONNX format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3c563e-535f-431f-b49c-b2008afacf6f",
   "metadata": {},
   "source": [
    "## Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f20ffb88-1685-4448-9af4-a981d83e94a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8df2bcd-d5e2-4fa3-8b68-bf8270d021d3",
   "metadata": {},
   "source": [
    "## Download model\n",
    "You can download the model of your choice (different sizes and characteristics) from here: https://github.com/ultralytics/yolov5#pretrained-checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24297e76-2a68-4885-a070-1880eac3f902",
   "metadata": {},
   "source": [
    "## Export the model to ONNX\n",
    "- Eventually modify the image size if you selected a model with the \"6\" suffix, as image size is 1280 (and not 640)\n",
    "- Stay at opset 16 for the moment for OpenVino model server compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96665823-af2c-43ed-a828-df19dcdf612f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=data/coco128.yaml, weights=['yolov5n.pt'], imgsz=[640], batch_size=1, device=cpu, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=16, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['onnx']\n",
      "YOLOv5 ðŸš€ 2023-3-13 Python-3.9.14 torch-1.13.1+cu117 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov5n.pt with output shape (1, 25200, 85) (3.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.13.1...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 2.7s, saved as yolov5n.onnx (7.6 MB)\n",
      "\n",
      "Export complete (4.5s)\n",
      "Results saved to \u001b[1m/opt/app-root/src/model-benchmark\u001b[0m\n",
      "Detect:          python detect.py --weights yolov5n.onnx \n",
      "Validate:        python val.py --weights yolov5n.onnx \n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5n.onnx')  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "!python export.py --weights yolov5n.pt --include onnx --imgsz 640 --opset 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faf82da-1a30-4bb6-bdbc-ee641ebbe24b",
   "metadata": {},
   "source": [
    "## Save your model file to your storage location\n",
    "Your ONNX model will have the same name as the one you downloaded, but with an `.onnx` extension."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
